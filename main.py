import streamlit as st
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
import os

# ğŸŒ„ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ú©Ù„ ØµÙØ­Ù‡
page_bg = """
<style>
[data-testid="stAppViewContainer"] {
    background-image: url("https://github.com/Goharshadi-m/ethnicity-app/blob/main/header.jpg");
    background-size: cover;
    background-position: center;
    background-repeat: no-repeat;
}
</style>
"""
st.markdown(page_bg, unsafe_allow_html=True)






[data-testid="stHeader"] {
    background: rgba(0,0,0,0); /* Ø­Ø°Ù Ù‡Ø¯Ø± Ø³ÙÛŒØ¯ Ø¨Ø§Ù„Ø§ÛŒ ØµÙØ­Ù‡ */
}

[data-testid="stSidebar"] {
    background: rgba(255, 255, 255, 0.5); /* Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ù†ÛŒÙ…Ù‡ Ø´ÙØ§Ù */
}

.block-container {
    background-color: rgba(255, 255, 255, 0.75); 
    border-radius: 15px;
    padding: 20px;
}
</style>
"""

st.markdown(page_bg, unsafe_allow_html=True)


# ====== ØªÙ†Ø¸ÛŒÙ…Ø§Øª ======
IMG_SIZE = 224
ethnic_labels = ['Arab', 'Iranian', 'IranianJews', 'Pashtun', 'Turkic']
iranian_labels = ['Baluch', 'Gilak', 'Hormozgani', 'Kurd', 'Lur', 'South_Khorasan', 'Yazdi']
colors = ['#66b3ff', '#ff9999', '#99ff99', '#ffcc99', '#c2c2f0']

# ====== Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ======
@st.cache_resource
def load_models():
    model = load_model("ethnicity_model.keras")
    model_irani = load_model("ethnicity_model_irani.keras")
    return model, model_irani

model, model_irani = load_models()

# ====== Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù‚ÙˆØ§Ù… ======
def load_ethnic_images():
    prepared_images = {}
    target_size = (100, 100)  # ğŸ‘ˆ Ù‡Ù…Ù‡ Ø¹Ú©Ø³â€ŒÙ‡Ø§ ÛŒÚ© Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø«Ø§Ø¨Øª
    for label in ethnic_labels:
        img_path = f"{label}.jpg"
        if os.path.exists(img_path):
            img = Image.open(img_path).convert("RGBA")
            img = img.resize(target_size, Image.Resampling.LANCZOS)  # ğŸ‘ˆ ØªØºÛŒÛŒØ± Ø§ÛŒÙ†Ø¬Ø§
            prepared_images[label] = img
    return prepared_images

prepared_images = load_ethnic_images()

# ====== Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ======
def preprocess_image(uploaded_file):
    img = Image.open(uploaded_file).convert("RGB")
    img = img.resize((IMG_SIZE, IMG_SIZE))
    img = img.convert("L")
    img_array = image.img_to_array(img)
    img_array = np.repeat(img_array, 3, axis=-1)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    return img_array, Image.open(uploaded_file)

# ====== Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ======
def plot_ethnicity_pie(predictions_dict, prepared_images, center_img):
    labels = list(predictions_dict.keys())
    sizes = [predictions_dict[k] * 100 for k in labels]

    # Ø§ØµÙ„Ø§Ø­ Ø³Ø§ÛŒØ² wedge Ù‡Ø§
    plot_sizes = []
    for size in sizes:
        if size < 10 and size > 0:
            plot_sizes.append(10)
        elif size == 0:
            plot_sizes.append(0)
        else:
            plot_sizes.append(size)

    total_plot_size = sum(plot_sizes)
    if total_plot_size > 0:
        plot_sizes = [s / total_plot_size * 100 for s in plot_sizes]
    else:
        plot_sizes = [0] * len(sizes)

    # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±
    fig, ax = plt.subplots(figsize=(8, 8))
    wedgeprops = {'width': 0.4}
    wedges, texts = ax.pie(plot_sizes, labels=None, colors=colors, startangle=140, wedgeprops=wedgeprops)

    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø±Ú†Ø³Ø¨ Ùˆ ØªØµÙˆÛŒØ± Ù‡Ø± Ù‚ÙˆÙ…
    for i, wedge in enumerate(wedges):
        angle = (wedge.theta2 + wedge.theta1) / 2.
        radius = 1.1
        x = radius * np.cos(np.deg2rad(angle))
        y = radius * np.sin(np.deg2rad(angle))

        original_percentage = sizes[i]
        label = labels[i]

        if original_percentage > 0:
            ax.text(x, y, f"{label}: {original_percentage:.1f}%", ha='center', va='center', fontsize=9)

        if label in prepared_images and original_percentage > 0:
            img_to_add = prepared_images[label]
            imagebox_inside = OffsetImage(img_to_add, zoom=0.3)
            inner_radius = 1 - wedgeprops['width']
            outer_radius = 1
            image_radius_position = (inner_radius + outer_radius) / 2.0
            x_img = image_radius_position * np.cos(np.deg2rad(angle))
            y_img = image_radius_position * np.sin(np.deg2rad(angle))
            ab_inside = AnnotationBbox(imagebox_inside, (x_img, y_img), frameon=False, pad=0.0)
            ax.add_artist(ab_inside)

    # ØªØµÙˆÛŒØ± Ù…Ø±Ú©Ø²ÛŒ
    if center_img is not None:
        inner_hole_diameter = 1 - wedgeprops['width']
        img_size_for_center = int(plt.rcParams['figure.figsize'][0] * fig.dpi * inner_hole_diameter * 0.7)
        center_img_resized = center_img.resize((img_size_for_center, img_size_for_center), Image.Resampling.LANCZOS)

        # Ù…Ø§Ø³Ú© Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ
        mask = Image.new('L', (img_size_for_center, img_size_for_center), 0)
        draw = ImageDraw.Draw(mask)
        draw.ellipse((0, 0, img_size_for_center, img_size_for_center), fill=255)
        center_img_resized.putalpha(mask)

        imagebox_center = OffsetImage(center_img_resized, zoom=1)
        ab_center = AnnotationBbox(imagebox_center, (0, 0), frameon=False, pad=0)
        ax.add_artist(ab_center)

    ax.axis('equal')
    plt.tight_layout()
    st.pyplot(fig)

# ====== Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ======

st.title("ğŸŒ Ø³Ø§Ù…Ø§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ù‚ÙˆÙ…ÛŒØª")
st.write("ÛŒÚ© ØªØµÙˆÛŒØ± Ù¾Ø±ØªØ±Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ù…Ø¯Ù„ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ù‡Ø¯.")

uploaded_file = st.file_uploader("ØªØµÙˆÛŒØ± Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    st.image(uploaded_file, caption="ØªØµÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ", use_container_width=True)

    img_array, original_img = preprocess_image(uploaded_file)
    predictions = model.predict(img_array)[0]
    predictions_irani = model_irani.predict(img_array)[0]

    predictions_dict = dict(zip(ethnic_labels, predictions))
    predictions_irani_dict = dict(zip(iranian_labels, predictions_irani))

    st.subheader("ğŸ”¹ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ù‚ÙˆÙ…ÛŒ Ø§ØµÙ„ÛŒ:")
    for k, v in predictions_dict.items():
        st.write(f"{k}: {v:.2%}")

    st.subheader("ğŸ”¹ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø²ÛŒØ±Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ:")
    for k, v in predictions_irani_dict.items():
        st.write(f"{k}: {v:.2%}")

    st.subheader("ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØªØµØ§ÙˆÛŒØ±")
    plot_ethnicity_pie(predictions_dict, prepared_images, original_img)




